{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/tcapelle/torch_moving_mnist/blob/main/training_nbs/03_ddpm_miniai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{next-frame-pred} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa3d1652",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models with miniai\n",
    "<!--- @wandbcode{next-frame-pred} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c4f01",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a0a9a-a9d6-4e6e-b59a-66cfaedb740f",
   "metadata": {},
   "source": [
    "I actually switched to a mini version of miniai that Johno Whitaker put together: https://github.com/johnowhitaker/miniminiai\n",
    "> It is just a simpler substed of code from Jeremy's `miniai`, basically everythin in a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2c4ce-8ec0-4304-9128-e50afe7c77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install miniminiai wandb diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de6aee-7e80-4ea4-89de-fcf1fe5cc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "import fastcore.all as fc\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.nn import init\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from diffusers import UNet2DModel, DDIMScheduler\n",
    "\n",
    "from miniminiai import DataLoaders, show_images, Learner, AccelerateCB, ProgressCB, MetricsCB, BatchSchedCB, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb2d883-6db2-4a1f-b699-ff8343df0fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray_r'\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f553bd6",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f2dfb-9676-4f50-bde0-10cef777e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(    \n",
    "    epochs = 15,\n",
    "    model_name=\"ddpm_mmnist_miniai\",\n",
    "    noise_steps=1000,\n",
    "    seed = 42,\n",
    "    batch_size = 128,\n",
    "    img_size = 40,\n",
    "    device = \"cuda\",\n",
    "    use_wandb = True,\n",
    "    num_workers=2,\n",
    "    num_frames=3,\n",
    "    lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d98528",
   "metadata": {},
   "source": [
    "By default we run on the 20k samples dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bad40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DATASET_AT = 'miniai_ddpm/MMNIST40_128k:latest'\n",
    "DATASET_AT = 'miniai_ddpm/MMNIST40_20k:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7e9d7-703d-472a-b19f-0610fffd77d8",
   "metadata": {},
   "source": [
    "Let's grab a precomputed MMNIST dataset from a W&B artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5b719-3724-49ec-8fc1-484c295bfc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "dataset = api.artifact(DATASET_AT)\n",
    "dataset_folder = Path(dataset.download())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca017f-768a-4e77-b621-bd467a31841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torch.load(next(dataset_folder.glob(\"*.pt\"))) - 0.5\n",
    "# ds = ds[0:3000] # to debug your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3792e17-baac-40bc-929c-2edf3b45db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.device, ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc30488-4770-4ad6-b00c-1075d31d92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_val = int(0.9*len(ds))\n",
    "train_ds = ds[:split_val].squeeze()\n",
    "valid_ds = ds[split_val:].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca383ebe-cabf-44fb-863d-7c9d73f6624b",
   "metadata": {},
   "source": [
    "Let's look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9570da-44a8-4d2f-bf54-3ae24f52a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = train_ds[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(xb.reshape(-1, 1, config.img_size, config.img_size), imsize=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25359f7-b231-41e0-b5b0-0ded8416ec8d",
   "metadata": {},
   "source": [
    "We will use the same noisify function as the one from the fastai course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51937482-2c44-45e3-bc79-ce433fd19003",
   "metadata": {},
   "outputs": [],
   "source": [
    "betamin,betamax,n_steps = 0.0001,0.02, 1000\n",
    "beta = torch.linspace(betamin, betamax, n_steps)\n",
    "alpha = 1.-beta\n",
    "alphabar = alpha.cumprod(dim=0)\n",
    "sigma = beta.sqrt()\n",
    "\n",
    "def noisify_ddpm(x0):\n",
    "    \"Noise by ddpm\"\n",
    "    device = x0.device\n",
    "    n = len(x0)\n",
    "    t = torch.randint(0, n_steps, (n,), dtype=torch.long)\n",
    "    ε = torch.randn(x0.shape, device=device)\n",
    "    ᾱ_t = alphabar[t].reshape(-1, 1, 1, 1).to(device)\n",
    "    xt = ᾱ_t.sqrt()*x0 + (1-ᾱ_t).sqrt()*ε\n",
    "    return xt, t.to(device), ε"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecb4a50-524b-4936-9990-5d80ad39259a",
   "metadata": {},
   "source": [
    "We wrap the noisify func and apply it to the last frame of the sequence. We refactor this in the `NoisifyDataloader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ae187-faf5-4a12-afed-24c8879d0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisify_last_frame(frames, noise_func):\n",
    "    \"Noisify the last frame of a sequence\"\n",
    "    past_frames = frames[:,:-1]\n",
    "    last_frame  = frames[:,-1:]\n",
    "    noise, t, e = noise_func(last_frame)\n",
    "    return torch.cat([past_frames, noise], dim=1), t, e\n",
    "\n",
    "def noisify_collate(noise_func): \n",
    "    def _inner(b): \n",
    "        \"Collate function that noisifies the last frame\"\n",
    "        return noisify_last_frame(default_collate(b), noise_func)\n",
    "    return _inner\n",
    "\n",
    "class NoisifyDataloader(DataLoader):\n",
    "    \"\"\"Noisify the last frame of a dataloader by applying \n",
    "    a noise function, after collating the batch\"\"\"\n",
    "    def __init__(self, dataset, *args, noise_func=noisify_ddpm, **kwargs):\n",
    "        super().__init__(dataset, *args, collate_fn=noisify_collate(noise_func), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, t, ε = noisify_last_frame(xb[:4], noisify_ddpm)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b7480-4bed-4bf5-9f5b-8fd2d267a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb72cd-1325-47b9-ae9e-4e78c1755f23",
   "metadata": {},
   "source": [
    "Let's show the noisy last frame with the noise level as title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ac781",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = fc.map_ex(t, '{}')\n",
    "titles = fc.concat(zip([[None,None,None]]*len(titles), titles)) \n",
    "show_images(xt.reshape(-1, 1, config.img_size, config.img_size), imsize=1.5, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f26317",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c121312e-0f67-47ab-a056-f789daba96b4",
   "metadata": {},
   "source": [
    "A better init for the UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ddpm(model):\n",
    "    for o in model.down_blocks:\n",
    "        for p in o.resnets:\n",
    "            p.conv2.weight.data.zero_()\n",
    "            for p in fc.L(o.downsamplers): init.orthogonal_(p.conv.weight)\n",
    "\n",
    "    for o in model.up_blocks:\n",
    "        for p in o.resnets: p.conv2.weight.data.zero_()\n",
    "\n",
    "    model.conv_out.weight.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d533268-3093-4e42-a81e-3c2fe5c189f2",
   "metadata": {},
   "source": [
    "Create the noisified DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba249101-5448-4657-93d0-04ecd9c4f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(NoisifyDataloader(train_ds, config.batch_size, num_workers=config.num_workers, pin_memory=True, shuffle=True), \n",
    "                  NoisifyDataloader(valid_ds, config.batch_size, num_workers=config.num_workers, shuffle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296410d6-9844-4ae5-b767-2b12681bf1fd",
   "metadata": {},
   "source": [
    "Standard DDIM sampler from Diffuser wrapped to use the last frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def diffusers_sampler(model, past_frames, sched, **kwargs):\n",
    "    \"Using Diffusers built-in samplers\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    past_frames = past_frames.to(device)\n",
    "    new_frame = torch.randn_like(past_frames[:,-1:], dtype=past_frames.dtype, device=device)\n",
    "    preds = []\n",
    "    pbar = progress_bar(sched.timesteps, leave=False)\n",
    "    for t in pbar:\n",
    "        pbar.comment = f\"DDIM Sampler: frame {t}\"\n",
    "        noise = model(torch.cat([past_frames, new_frame], dim=1), t).sample\n",
    "        new_frame = sched.step(noise, t, new_frame, **kwargs).prev_sample\n",
    "        preds.append(new_frame.float().cpu())\n",
    "    return preds[-1]\n",
    "\n",
    "def ddim_sampler(steps=350, eta=1.):\n",
    "    \"DDIM sampler, faster and a bit better than the built-in sampler\"\n",
    "    ddim_sched = DDIMScheduler()\n",
    "    ddim_sched.set_timesteps(steps)\n",
    "    return partial(diffusers_sampler, sched=ddim_sched, eta=eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd88ef-a8ea-4798-83f3-42f2394442a1",
   "metadata": {},
   "source": [
    "A simple WandbCB for `miniminiai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d943cea-2c94-4adc-83aa-2269ecdf9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbCB(Callback):\n",
    "    \"Hacky W&B callback\"\n",
    "    order = MetricsCB.order+1\n",
    "    def __init__(self, model_name=None): self.model_name = model_name\n",
    "    def before_fit(self, learn):\n",
    "        if wandb.run is None:\n",
    "            raise Exception(\"You have to run fit inside a wandb run\")\n",
    "        if hasattr(learn, 'metrics'): \n",
    "            self._log_copy = learn.metrics._log\n",
    "            learn.metrics._log = self._log\n",
    "        self.losses = []\n",
    "\n",
    "    def _log(self, d):\n",
    "        self._log_copy(d)\n",
    "        wandb.log(d)\n",
    "    \n",
    "    def after_batch(self, learn):\n",
    "        if learn.training:\n",
    "            wandb.log({\"train_loss\":learn.loss.item()})\n",
    "                       # \"lr\":learn.schedo.get_last_lr()[0]})\n",
    "    def after_fit(self, learn):\n",
    "        if self.model_name is not None:\n",
    "            model_name = f\"{wandb.run.id}_{self.model_name}\"\n",
    "            at = wandb.Artifact(model_name, type=\"model\")\n",
    "            torch.save(learn.model.state_dict(), f\"models/{self.model_name}.pth\")\n",
    "            at.add_file(f\"models/{self.model_name}.pth\")\n",
    "            wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5fad6e-4290-42ec-a6d4-7ec4e61c41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_wandb_image(img):\n",
    "    \"Stack the images horizontally\"\n",
    "    return wandb.Image(torch.cat(img.split(1), dim=-1).cpu().numpy())\n",
    "\n",
    "def log_images(model, xt):\n",
    "    \"Sample and log images to W&B\"\n",
    "    samples = ddim_sampler()(model, xt)\n",
    "    frames = torch.cat([xt.to(samples[-1].device), samples], dim=1)\n",
    "    wandb.log({\"sampled_images\": [to_wandb_image(img) for img in frames]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d806da23-3719-4728-901e-18f4a789c7ae",
   "metadata": {},
   "source": [
    "Let's log some predictions to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948ad53-d375-4df4-b081-6af673d92057",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogPreds(Callback):\n",
    "    \"Log samples to W&B\"\n",
    "    order = WandbCB.order+1\n",
    "    def __init__(self, n_preds=10, log_every=1):\n",
    "        self.log_every = log_every\n",
    "        self.n_preds = n_preds\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        dt = learn.dls.valid\n",
    "        xt, t, ε = next(iter(dt))\n",
    "        self.xt = xt[:self.n_preds,:-1,...]\n",
    "    \n",
    "    def after_epoch(self, learn):\n",
    "        if not learn.training and (learn.epoch%self.log_every==0):\n",
    "            log_images(learn.model, self.xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f54712",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMCB(Callback):\n",
    "    \"We need to recover the UNet output from the OutputDict\"\n",
    "    def after_predict(self, learn): learn.preds = learn.preds.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea59fc-dfdd-4930-9700-e1bd4bc088b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax = config.epochs * len(dls.train)\n",
    "sched = partial(optim.lr_scheduler.OneCycleLR, max_lr=config.lr, total_steps=tmax)\n",
    "opt_func = partial(optim.Adam, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c9d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet2DModel(in_channels=4, out_channels=1, block_out_channels=(16, 32, 64, 128), norm_num_groups=8)\n",
    "init_ddpm(model)\n",
    "cbs = [DDPMCB(), ProgressCB(plot=True), MetricsCB(), BatchSchedCB(sched), AccelerateCB(n_inp=2)]\n",
    "learn = Learner(model, dls, nn.MSELoss(reduction=\"sum\"), lr=config.lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d13195",
   "metadata": {},
   "source": [
    "Let's check the Callbacks present in the Learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57512085-2c06-46b4-a177-3a712b9a421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{cb.__class__.__name__:cb.order for cb in learn.cbs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eaacf7",
   "metadata": {},
   "source": [
    "We will log the samples to W&B every `log_every` epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9cdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=\"miniminiai_ddpm\", config=config):\n",
    "    learn.fit(config.epochs, cbs=[WandbCB(\"test_model\"), LogPreds(log_every=1)])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
